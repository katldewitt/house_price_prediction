---
title: "Stat 420 Final Project - Modeling"
author: "Shashank Thakur, Net ID: sthakur5"
date: '27th July 2022'
output:
  html_document: 
    theme: readable
    toc: yes  
  pdf_document: default
urlcolor: cyan
editor_options: 
  chunk_output_type: console
---

# Modeling California Housing Project Data Set


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80, fig.alin = "center")

library(ggplot2)
library(faraway)
library(lmtest)
library(knitr)
```


## Initialization

Read the data file to be used for this project.
```{r read_data_file}
setwd("/Users/srthakur/Documents/GitHub/house_price_prediction/200_Final_Report")
ca_housing_data = read.csv('housing.csv')
# head(ca_housing_data)
```

Initialize global variables.
```{r}
# build different models to test the performance
n_models = 8
# create a vector list of models to pass to various functions
cahoudta_models = vector("list", length = n_models)
cahoudta_model_names = vector("character", length = n_models)
# Train-Test Split Ration
tr_pct = 0.70
```

## Helper Functions

**Function   : **`model_performance_metrics` will generate model performance metrics such as RMSE and R-squared, etc.

**Inputs: **

*models      : * A list of models to generate the performance metrics

*model_names : * Names of the models passed to the function

**Returns    : ** Returns a data frame with following performance metrics as columns and a row for each model 
                  provided in `model_names` as input.

                  R2: R-Squared
                  ADJR2: Adjusted R-Squared
                  RMSE: Root Mean Square Error
                  LOOCV_RMSE: Leave One Out Cross Validated RMSE
                  Coefs: Total number of coefficients in the model
```{r}
model_performance_metrics = function(models, model_names){
  # Calculate model names and total numbers
  n_mod = length(models)
  # Initialize the data frame to be be built by the function
  perf_metrics_df = data.frame(
    row.names = model_names,
    "R2" = rep(0L, n_mod),
    "ADJR2" = rep(0L, n_mod),
    "RMSE" = rep(0L, n_mod),
    "LOOCV_RMSE" = rep(0L, n_mod),
    "Coefs" = rep(0L, n_mod)
  )
  
  for (idx in 1:n_mod){
    perf_metrics_df[model_names[idx], "R2"] = summary(models[[idx]])$r.squared 
    perf_metrics_df[model_names[idx], "ADJR2"] = summary(models[[idx]])$adj.r.squared 
    perf_metrics_df[model_names[idx], "RMSE"] = sqrt(mean(resid(models[[idx]]) ^ 2)) 
    perf_metrics_df[model_names[idx], "LOOCV_RMSE"] = sqrt(mean((resid(models[[idx]]) / 
                                                                   (1 - hatvalues(models[[idx]]))) ^ 2)) 
    perf_metrics_df[model_names[idx], "Coefs"] = length(coef(models[[idx]]))
  }
  return(perf_metrics_df)
}
```

**Function: ** `models_RMSE_by_data` to calculate root mean square for input data on the model

**Input:** 

*models      :* A list of fitted model passed as a parameter.

*model_names : * Names of the models passed to the function

*data        :* The actual data which will be used to calculate predicted values and RMSE for each model

**Returns:** The function will a data frame with value of RMSE on input data for each model in list
```{r}
models_RMSE_by_data = function(models, model_names, data){
  # Calculate model names and total number of models
  n_mod = length(models)
  # Initialize the data frame to be be built by the function
  RMSE_df = data.frame(
    row.names = model_names,
    "RMSE" = rep(0L, n_mod)
  )
  y_i = data[["median_house_value"]]
  for (idx in 1:n_mod){
    y_hat = exp(predict(models[[idx]], newdata = data))
    RMSE_df[idx, "RMSE"] = sqrt(mean((y_i - y_hat) ^ 2))
  }
  return(RMSE_df)
}
```


## Data cleaning

During initial data analysis phase, we determined that some of the columns have high multicollinearity and we decided to drop those columns. One example of such column is `total_bedrooms` which not only has multicollinearity with `total_rooms` but also has some missing data. We will drop this column to allow for modeling **response** variable `median_house_value`.
```{r}
ca_housing_data = subset(ca_housing_data, select = -total_bedrooms)
head(ca_housing_data)
```
We have another column `ocean_proximity` which is a categorical variable indicating how close the block is from ocean. 
```{r}
table(ca_housing_data$ocean_proximity)
```
As can be seen, this column has 5 different categories. The `ISLAND` category has only 5 observations. During initial analysis, our team determined that `ISLAND` has high leverage on the predicting response variable `median_house_value` which is problematic for our purpose. We will be dropping the rows from data set with `ISLAND` category and coercing the predictor `ocean_proximity` to be categorical.

```{r}
ca_housing_data = subset(ca_housing_data, 
                         subset = ca_housing_data$ocean_proximity != "ISLAND")
table(ca_housing_data$ocean_proximity)
# Coerce ocean_proximity to a factor variable
ca_housing_data$ocean_proximity = as.factor(ca_housing_data$ocean_proximity)
is.factor(ca_housing_data$ocean_proximity)
levels(ca_housing_data$ocean_proximity)
```

## Model Building

Now that we have data cleaned, we will proceed with building a model. The very first step we will take is to divide data into train and test. Based on total number of observations we've, team has decided to use 70%-30% split for train-test data.
```{r}
set.seed(420072022)
# Randomly select train indexes
cahoudta_trn_idx = sample(nrow(ca_housing_data), 
                          size = trunc(tr_pct * nrow(ca_housing_data)))
# Split into train and test data sets based on the index
ca_housing_data.tr = ca_housing_data[cahoudta_trn_idx, ]
ca_housing_data.te = ca_housing_data[-cahoudta_trn_idx, ]

n_tr_rows = nrow(ca_housing_data.tr)
n_te_rows = nrow(ca_housing_data.te)
```

Next we will build models and start running tests.

```{r}
cahoudta_full_add_model = lm(log(median_house_value) ~ ., data = ca_housing_data.tr)
# summary(cahoudta_full_add_model)
```

Checking if there is multi-collinearity in the full fitted additive model. Following code snippet outputs all the predictors which has high variation inflation factors.
```{r}
high_vif_predictors = vif(cahoudta_full_add_model) > 5
high_vif_pred_vals = vif(cahoudta_full_add_model)[high_vif_predictors]
sort(high_vif_pred_vals)
```

Based on variable inflation factors the predictors `households` and `latitude` can be dropped. 

Lets try backward BIC search from the full additive model.
```{r}
cahoudta_add_bckwd_bic_model = step(cahoudta_full_add_model, 
                                    direction = "backward",
                                    k = log(n_tr_rows),
                                    trace = 0)
```

Lets try two way interaction full additive model.
```{r}
cahoudta_2int_add_model = lm(log(median_house_value) ~ . ^ 2, data = ca_housing_data.tr)
```

Lets try backward BIC search from two way interaction full additive model.
```{r}
cahoudta_2int_bckwd_bic_model = step(cahoudta_2int_add_model, 
                                    direction = "backward",
                                    k = log(n_tr_rows),
                                    trace = 0)
```

We will run pairs plot to check any obvious trends in predictors compared to the response variable `median_house_value`.
```{r fig.height=8, fig.width=12}
pairs(subset(ca_housing_data.tr, 
             select = -ocean_proximity), 
      col = "orchid2")
```

Based on pairs plot, for response variable `median_house_value`

- `median_income`, `households`, `total_rooms` has some polynomial relationship.

- `housing_mdeian_age` has lot of variance and needs variable transformation.

- Either one of `latitude` or `longitude` can be eliminated


Lets drop the predictors `households` and `latitude` with high VIF.
```{r}
predictor_variables = colnames(ca_housing_data.tr)[-which(colnames(ca_housing_data.tr)
                                                          == "median_house_value")]
drop_cols = which(colnames(ca_housing_data.tr) == "median_house_value" | 
                    colnames(ca_housing_data.tr) == "households" | 
                    colnames(ca_housing_data.tr) == "latitude")
smaller_predictors = colnames(ca_housing_data.tr)[-drop_cols]
less_preds = paste0("log(median_house_value) ~ ", paste(smaller_predictors, collapse = " + "))
cahoudta_lowvif_add_mod = lm(formula = less_preds, data = ca_housing_data.tr)
```

Lets add 2 way interaction for above model to check the performance.
```{r}
less_preds_2int = paste0("log(median_house_value) ~ (", paste(smaller_predictors, collapse = " + "), ") ^ 2")
cahoudta_lowvif_2int_mod = lm(formula = less_preds_2int, data = ca_housing_data.tr)
```

To increase complexity, lets try a degree 2 polynomial for reduced predictors based on vif above. Also we have to exclude the categorical predictor `ocean_proximity` from polynomial formula.
```{r}
drop_cols = which(colnames(ca_housing_data.tr) == "median_house_value" | 
                    colnames(ca_housing_data.tr) == "households" | 
                    colnames(ca_housing_data.tr) == "latitude")
reduced_predictors = colnames(ca_housing_data.tr)[-drop_cols]
less_preds = paste0("log(median_house_value) ~ ", paste(smaller_predictors, collapse = " + "))
further_reduced_predictors = reduced_predictors[-which(reduced_predictors == "ocean_proximity")]
less_poly_preds = paste0(" + I(", paste(further_reduced_predictors, collapse = " ^ 2) + I("), " ^ 2)")
poly_formula = paste0(less_preds, less_poly_preds)
message("Polynomial Formula: ", poly_formula)
cahoudta_lowvif_2poly_mod = lm(formula = poly_formula, data = ca_housing_data.tr)
# summary(cahoudta_lowvif_2poly_mod)$coef
```

I will add back `latitude` and test if that gives better results.
```{r}
drop_cols = which(colnames(ca_housing_data.tr) == "median_house_value" | 
                    colnames(ca_housing_data.tr) == "households")
lesser_predictors = colnames(ca_housing_data.tr)[-drop_cols]
less_preds = paste0("log(median_house_value) ~ ", paste(lesser_predictors, collapse = " + "))
message("Model 8: Formula: ", less_preds)
cahoudta_lola_add_mod = lm(formula = less_preds, data = ca_housing_data.tr)
```



Test the performance metrics for the model(s).
```{r}
cahoudta_models[[1]] = cahoudta_full_add_model
cahoudta_model_names[[1]] = "cahoudta_full_add_model"

cahoudta_models[[2]] = cahoudta_add_bckwd_bic_model
cahoudta_model_names[[2]] = "cahoudta_add_bckwd_bic_model"

cahoudta_models[[3]] = cahoudta_2int_add_model
cahoudta_model_names[[3]] = "cahoudta_2int_add_model"

cahoudta_models[[4]] = cahoudta_2int_bckwd_bic_model
cahoudta_model_names[[4]] = "cahoudta_2int_bckwd_bic_model"

cahoudta_models[[5]] = cahoudta_lowvif_add_mod
cahoudta_model_names[[5]] = "cahoudta_lowvif_add_mod"

cahoudta_models[[6]] = cahoudta_lowvif_2int_mod
cahoudta_model_names[[6]] = "cahoudta_lowvif_2int_mod"

cahoudta_models[[7]] = cahoudta_lowvif_2poly_mod
cahoudta_model_names[[7]] = "cahoudta_lowvif_2poly_mod"

cahoudta_models[[8]] = cahoudta_lola_add_mod
cahoudta_model_names[[8]] = "cahoudta_lola_add_mod"

# Model performance on train data
kable(model_performance_metrics(cahoudta_models, cahoudta_model_names),
      col.names = c("R-Squared", 
                    "Adjusted R-Squared", 
                    "RMSE", 
                    "LOOCV RMSE", 
                    "Coefficients"),
      caption = "Comparative Model Performance Metrics")

# Test RMSE
kable(models_RMSE_by_data(cahoudta_models, 
                          cahoudta_model_names, 
                          ca_housing_data.te),
      col.names = c("Test RMSE"),
      caption = "Test Root Mean Square Error for Each Model")
```

As we can see from the results that the backward BIC search doesn't help in reducing number of beta parameters. Both the full model `cahoudta_full_add_model` and backward step wise search model `cahoudta_add_bckwd_bic_model` has same number of parameters i.e. 11. So we tried to reduce the train-test split to 50%-50%. Even after that the backward BIC search reduced only 1 parameter from 11 to 10 with very negligible loss in adjusted r-squared.


## Model Selection

Work in progress...